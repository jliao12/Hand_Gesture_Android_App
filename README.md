# Hand_Gesture_Android_App
The main purpose of the project is to give student a taste of how picture or video-based hand gesture recognition work. 
Despite that the voice control smart assistants, like Siri or Alex, are popular these days, there are still rooms for hand gesture control assistant 
for specific people or using scenario. For example, hand gesture can be very useful to deaf people or old people who can only use hand gesture to express themselves. Hand gesture can be also useful when working in quiet area without disturbing others. Also, the basic knowledge behind the hand gesture recognition is similar to picture or video feature recognition. With the idea that students can learn from this project, one can apply these knowledge when trying to have computers to recognize loads of pictures or videos in one go. In addition, this project provides students the chance to practice on how to develop an android mobile application that can be ran on smart phones by using the Android Studio development platform, which is a very practical and useful skills that can be later applied to real world tasks. 
## Part 1
The first part required to use the Android Studio to develop a mobile application with three actives (interfaces). The first activity will have the drop down list that contain all 17 gesture options (including number 0 to 9 and lights on and off, fan on and off, fan speed increase or decrease fan speed and set thermostat). After choosing one of the 17 gestures, the second activity will pop up with the corresponding short video of how the gesture should be done. The video should be able to replay for at least 3 times. On second activity, another bottom, “Practice”, should be included. Clicking the bottom will open the camera in video mode and record the gesture practiced by the user for 5 seconds. After confirming the video, the third activity will pop up with a bottom “Upload” on it. The upload bottom will send the recorded video to the local server and also take the user back to the first activity. The expert videos are provided, and it is recommended to used Flask to build the local server. Student should use the application to practice three times for each of the 17 gestures and create 51 videos.

## Part 2
The second part of the project is about gesture recognition through Convolutional neural network (CNN) deep learning algorithm via python platform. The 51 videos that recorded from part 1 will be used as the training videos and the base codes that can do frame extraction and feature extraction are provided. The CNN model that was built by recognizing alphabets is also provided. After training the model with the video, the provided test video will be used to validate to check the accuracy rate of the gesture recognition.
## Application
The first part is an Android application, please download the whole file and open with Android Studio. The second part is based on Python, the folder has sample video and cut frame, you may use your own video and frames. For detailed explanation, please refer to the 535_portfolio.pdf for additional information.
